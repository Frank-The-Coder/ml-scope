# ML-Scope Architecture

## System Overview

ML-Scope is a modular, scalable, and real-time machine learning pipeline designed to integrate forecasting models, reinforcement learning (RL) agents, and robust queue management. It is equipped with resilience testing, experimental hyperparameter tuning, and hardware-aware optimizations to align with real-world system challenges.

The system aims to bridge forecasting and decision-making by connecting multiple dynamic components:

1. **Forecasting model**: Real-time prediction generation.
2. **Shared queue**: Centralized data pipeline for seamless integration.
3. **Reinforcement learning agent**: Adaptive decision-making based on real-time predictions.
4. **Experimental pipeline**: Automated hyperparameter tuning and resilience testing.
5. **Hardware compatibility**: Dynamic model optimizations for CPU and GPU support.

---

## Core Components

### 1. Prediction Queue

- **Purpose**: The backbone of the real-time pipeline, ensuring predictions flow seamlessly between forecasting and RL components.
- **Implementation**:
  - Managed by `multiprocessing.managers.BaseManager`.
  - Capped at 100 predictions to maintain efficiency and avoid overflow.
- **Data Flow**:
  1. Predictions generated by the LSTM forecasting model (`forecast_training.py`) are enqueued with timestamps.
  2. RL agent dequeues predictions in real time for adaptive decision-making.
  3. Queue operations are logged for performance analysis and debugging.

---

### 2. Forecasting Model

- **Purpose**: Generates time-series predictions for the RL agent.
- **Architecture**:
  - **LSTM-based**: Optimized for sequential data forecasting.
  - Dynamic model quantization applied for efficient CPU performance; GPU acceleration utilized when available.
- **Features**:
  - Integrates `torch.quantization` for hardware-aware optimization.
  - Automatic device detection (`cuda` or `cpu`) via `config/device_config.py`.
- **Integration**:
  - Enqueues predictions into the shared queue (`queue_server.py`).
  - Logs queue status using the monitoring system (`queue_monitor.py`).
  - Quantization ensures compatibility with resource-constrained devices.

---

### 3. Reinforcement Learning Agent

- **Purpose**: Learns optimal actions based on predictions and rewards from the queue.
- **Components**:
  - **Custom Gym Environment** (`SimpleEnv` in `rl_utils.py`): Models RL interactions with the prediction queue.
  - **QLearningAgent**: Implements Q-learning with hyperparameter configurability for learning rate, exploration rate, and discount factor.
- **Workflow**:
  1. RL agent dequeues predictions from the shared queue.
  2. Actions are taken based on the current state and predictions.
  3. Rewards are calculated dynamically and scaled.
  4. The Q-table is updated based on reward signals to improve decision-making over time.

---

### 4. Resilience Testing

- **Purpose**: Evaluates the system's ability to handle stress and high-load conditions.
- **Workflow**:
  - Rapid prediction generation via `resilience_testing.py` simulates burst scenarios.
  - Logs enqueue and dequeue operations to monitor latency and bottlenecks.
  - Tests system behavior during queue overflow, ensuring robust recovery mechanisms.

---

### 5. Experimental Pipeline

- **Purpose**: Automates hyperparameter tuning for RL model optimization.
- **Workflow**:
  - Runs experiments with various configurations of learning rate, exploration rate, and discount factor.
  - Monitors the RL agent's performance for each configuration, recording cumulative rewards and training stability.
  - Automatically stops RL training when all predictions are processed.
- **Features**:
  - Logs results for each experiment in a dedicated logging system.
  - Enables systematic exploration of hyperparameter effects on RL performance.

---

### 6. Logging and Monitoring System

- **Purpose**: Centralized and modular logging for all pipeline components.
- **Implementation**:
  - Base logging configured in `config/logging_config.py`.
  - Component-specific logs:
    - **Queue operations**: `queue_processing.log`
    - **RL training**: `rl_training.log`
    - **Forecasting model**: Custom logger for prediction generation.
- **Features**:
  - Logs include timestamps, prediction values, enqueue/dequeue delays, actions, and rewards.
  - Separate logs for each component prevent clutter and enable targeted debugging.

---

### 7. Hardware Compatibility

- **Purpose**: Ensure optimized performance on available hardware, including CPUs and GPUs.
- **Features**:
  - Automatic device detection using `torch.device`.
  - Quantized LSTM model for CPU efficiency via `torch.quantization`.
  - Dynamic execution paths for hardware-specific optimizations.

---

## Data Flow

1. **Prediction Generation**:

   - Forecasting model generates predictions and enqueues them into the shared queue.
   - Predictions include timestamps for monitoring enqueue delays.

2. **Real-Time Queue Management**:

   - RL agent dequeues predictions as they become available.
   - Queue operations are logged with detailed metrics.

3. **Reinforcement Learning**:

   - RL agent uses dequeued predictions to update its Q-table and take optimal actions.
   - Actions and rewards are logged for analysis.

4. **Resilience Testing**:

   - Rapid enqueue operations simulate high-load conditions.
   - Queue metrics and RL performance are monitored to identify bottlenecks.

5. **Hyperparameter Experimentation**:
   - Pipeline tests multiple configurations, logging results for each run.
   - Outputs include cumulative rewards and performance summaries for all hyperparameter combinations.

---

## Future Enhancements

1. **Advanced Forecasting Models**:

   - Extend the pipeline to include transformer-based models or hybrid architectures.

2. **Distributed Queue Management**:

   - Implement distributed queues for large-scale, multi-agent setups.

3. **Enhanced RL Algorithms**:

   - Integrate policy-based methods (e.g., DDPG, PPO) for continuous action spaces.

4. **Hardware-Specific Optimization**:

   - Add support for specialized hardware like AWS Neuron, AMD GPUs, or other AI accelerators.

5. **Real-Time Monitoring Dashboard**:
   - Visualize queue metrics, RL training progress, and hyperparameter performance in real time.
